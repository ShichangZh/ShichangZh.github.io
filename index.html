<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Shichang (Ray) Zhang </title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Info</div>
<div class="menu-item"><a href="index.html" class="current">Main</a></div>
<div class="menu-item"><a href="research.html">Research</a></div>
<div class="menu-item"><a href="teaching.html">Teaching</a></div>
<div class="menu-item"><a href="talks.html">Talks</a></div>
<div class="menu-item"><a href="miscellaneous.html">Miscellaneous</a></div>
<div class="menu-category">Links</div>
<div class="menu-item"><a href="https://ucla-dm.github.io/DM_website/">UCLA&nbsp;DM</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Shichang (Ray) Zhang </h1>
</div>
<table class="imgtable"><tr><td>
<a href="https://shichangzh.github.io/"><img src="img/bio2.jpg" alt="alt text" width="280px" height="320px" /></a>&nbsp;</td>
<td align="left"><h3>About Me</h3>
<p>I am Shichang (Ray) Zhang. I am a postdoctoral fellow at the <a href="https://d3.harvard.edu/" target=&ldquo;blank&rdquo;>D^3 Institute at Harvard University</a> working with Professor <a href="https://himalakkaraju.github.io/" target=&ldquo;blank&rdquo;>Hima Lakkaraju</a>. I received my Ph.D. in Computer Science from <a href="http://www.ucla.edu/" target=&ldquo;blank&rdquo;>University of California, Los Angeles (UCLA)</a> advised by Professor <a href="http://web.cs.ucla.edu/~yzsun/" target=&ldquo;blank&rdquo;>Yizhou Sun</a>. My Ph.D. research was generously supported by the <a href="https://www.jpmorgan.com/technology/artificial-intelligence/research-awards/phd-fellowship-2023" target=&ldquo;blank&rdquo;>J.P. Morgan Chase AI Ph.D. Fellowship</a> and the <a href="https://www.sciencehub.ucla.edu/2023-amazon-fellows/" target=&ldquo;blank&rdquo;>Amazon Fellowship</a>. Before UCLA, I received my M.S. and B.A., both in Statistics, from <a href="https://statistics.stanford.edu/" target=&ldquo;blank&rdquo;>Stanford</a> and <a href="https://statistics.berkeley.edu/" target=&ldquo;blank&rdquo;>Berkeley</a>, respectively. </p>
<p>My research aims to <b>scientifically understand AI to ensure it is trustworthy and beneficial to humanity</b>. I have developed principled methods to analyze and improve the trustworthiness of AI systems across the <b>full spectrum</b> from data to model to training: 
(1) Data-wise, I design methods to examine how data features drive AI decisions at inference time, with applications in <a href="https://arxiv.org/pdf/2401.08627" target=&ldquo;blank&rdquo;>science</a>, <a href="https://arxiv.org/pdf/2302.12465" target=&ldquo;blank&rdquo;>e-commerce</a>, and <a href="https://pubsonline.informs.org/doi/abs/10.1287/isre.2023.0029?journalCode=isre" target=&ldquo;blank&rdquo;>healthcare</a>. (2) Model-wise, I study large language models (LLMs) to reveal their <a href="https://arxiv.org/pdf/2504.02904" target=&ldquo;blank&rdquo;>internal mechanisms</a> and <a href="https://arxiv.org/pdf/2307.10635v2" target=&ldquo;blank&rdquo;>reasoning capabilities</a>, enabling task-specific <a href="https://arxiv.org/pdf/2406.09612" target=&ldquo;blank&rdquo;>interpretable models</a> built upon them. (3) Training-wise, I develop techniques to measure the training influence on AI behavior, providing new tools for <a href="https://openreview.net/pdf?id=ghp4GWDFd1" target=&ldquo;blank&rdquo;>training data assessment</a>, <a href="https://arxiv.org/pdf/2506.00175" target=&ldquo;blank&rdquo;>model auditing, and credit assignment to developers</a>. Collectively, my research moves beyond black-box empiricism toward a holistic scientific understanding of AI.</p>
<p><span style="color:red">I am on the academic job market for the 2025 to 2026 cycle. If you believe I am a good fit for your institution, please don't hesitate to reach out at shzhang AT hbs DOT edu.</span> <br />
<a href="cv/shichang_zhang_CV.pdf" target=&ldquo;blank&rdquo;>[CV]</a> <a href="https://drive.google.com/file/d/1kRY7HHc54eScmcCyeVQJoRkPgeimRV5i/view?usp=drive_link" target=&ldquo;blank&rdquo;>[Research Statement]</a> <a href="https://drive.google.com/file/d/1FopvxdYuSq7YW3zk5qjc-ovGYJrsVIiW/view?usp=drive_link" target=&ldquo;blank&rdquo;>[Teaching Statement]</a> <a href="https://www.youtube.com/watch?v=CSOPpdDn03M" target=&ldquo;blank&rdquo;>[Talk Sample]</a></p>
<h3>Contact</h3>
<p>Science and Engineering Complex (SEC) 6.220, 150 Western Ave, Boston, MA 02134 <br />
E-mail: <i>shzhang</i> AT hbs DOT edu <br />
<a href="https://scholar.google.com/citations?hl=en&amp;user=TYqG0x4AAAAJ&amp;view_op=list_works&amp;sortby=pubdate" target=&ldquo;blank&rdquo;>[Google Scholar]</a> <a href="https://github.com/ShichangZh" target=&ldquo;blank&rdquo;>[GitHub]</a> <a href="https://www.linkedin.com/in/shichang-ray-zhang-4430a4106/" target=&ldquo;blank&rdquo;>[LinkedIn]</a> <a href="https://x.com/shichangzhang" target=&ldquo;blank&rdquo;>[X]</a></p>
</td></tr></table>
<h2>What's New</h2>
<ul>
<li><p>[July 2025] Our paper on A Mechanistic View of How Post-Training Reshapes LLMs has been accepted by COLM 2025. <a href="https://arxiv.org/pdf/2504.02904" target=&ldquo;blank&rdquo;>[PDF]</a><br /></p>
</li>
<li><p>[June 2025] Selected as one of the top 10% of reviewers for KDD 2025 again for the February cycle. <br /></p>
</li>
<li><p>[Apr 2025] Our paper on A Mechanistic View of How Post-Training Reshapes LLMs has won the NENLP 2025 <b>Outstanding Paper Award</b>. <a href="https://arxiv.org/pdf/2504.02904" target=&ldquo;blank&rdquo;>[PDF]</a><a href="slides/2025_04_NENLP.pdf" target=&ldquo;blank&rdquo;>[slides]</a></p>
</li>
<li><p>[Apr 2025] Our paper on A Mechanistic View of How Post-Training Reshapes LLMs has been selected as Oral presentation for NENLP 2025.</p>
</li>
<li><p>[Apr 2025] Give a talk on AI Interpretability at Georgia Institute of Technology.</p>
</li>
<li><p>[Apr 2025] Give a talk on AI Interpretability at Emory University.</p>
</li>
<li><p>[Feb 2025] Serving as an Area Chair for ACL ARR 2025.</p>
</li>
<li><p>[Feb 2025] Our paper on Advancing Interpretability by Unifying Feature, Data and Model Component Attribution is on arXiv now. <a href="https://arxiv.org/pdf/2501.18887" target=&ldquo;blank&rdquo;>[PDF]</a></p>
</li>
<li><p>[Dec 2024] Selected as the top 10% of reviewers for KDD 2025. <br /></p>
</li>
<li><p>[Nov 2024] Our paper on LLM-based explainable molecular concept learning is accepted by COLING 2025. <a href="https://arxiv.org/pdf/2406.09612" target=&ldquo;blank&rdquo;>[PDF]</a><br /></p>
</li>
<li><p>[Oct 2024] Our paper on explainable graph learning for predicting ICU length of stay is accepted by ISR. <a href="https://pubsonline.informs.org/doi/epdf/10.1287/isre.2023.0029" target=&ldquo;blank&rdquo;>[PDF]</a> <br /></p>
</li>
<li><p>[Oct 2024] Our paper on generalized group data attribution is on arXiv now. <a href="https://arxiv.org/pdf/2410.09940" target=&ldquo;blank&rdquo;>[PDF]</a></p>
</li>
</ul>
<p><a href="news.html" target=&ldquo;blank&rdquo;>Find out older news</a></p>
<h2>Selected Publications and Preprints</h2>
<ol>
<li><p>How Post-Training Reshapes LLMs: A Mechanistic View on Knowledge, Truthfulness, Refusal, and Confidence <br />
Hongzhe Du*, Weikai Li*, Min Cai, Karim Saraipour, Zimin Zhang, Himabindu Lakkaraju, Yizhou Sun, <b>Shichang Zhang</b> (*equal contribution) <br />
COLM 2025 (NENLP <b>Outstanding Paper</b>) <a href="https://arxiv.org/pdf/2504.02904" target=&ldquo;blank&rdquo;>[PDF]</a> <a href="slides/2025_04_NENLP.pdf" target=&ldquo;blank&rdquo;>[slides]</a><br /></p>
</li>
<li><p>Towards Unified Attribution in Explainable AI, Data-Centric AI, and Mechanistic Interpretability <br />
<b>Shichang Zhang</b>, Tessa Han, Usha Bhalla, Himabindu Lakkaraju <br />
Preprint, Under Review <a href="https://arxiv.org/pdf/2501.18887" target=&ldquo;blank&rdquo;>[PDF]</a><br /></p>
</li>
<li><p>Automated Molecular Concept Generation and Labeling with Large Language Models <br />
Zimin Zhang*, Qianli Wu*, Botao Xia*, Fang Sun, Ziniu Hu, Yizhou Sun, <b>Shichang Zhang</b> (*equal contribution) <br />
COLING 2025 <a href="https://arxiv.org/pdf/2406.09612" target=&ldquo;blank&rdquo;>[PDF]</a> <a href="https://github.com/ziminz19/AutoMolCo" target=&ldquo;blank&rdquo;>[Code]</a><br /></p>
</li>
<li><p>An Explainable AI Approach using Graph Learning to Predict ICU Length of Stay <br />
Tianjian Guo, Indranil Bardhan, Ying Ding, <b>Shichang Zhang</b> <br />
ISR Oct. 2024 <a href="https://pubsonline.informs.org/doi/epdf/10.1287/isre.2023.0029" target=&ldquo;blank&rdquo;>[PDF]</a><br /></p>
</li>
<li><p>Predicting and Interpreting Energy Barriers of Metallic Glasses with Graph Neural Networks <br />
Haoyu Li*, <b>Shichang Zhang*</b>, Longwen Tang, Mathieu Bauchy, Yizhou Sun (*equal contribution) <br />
ICML 2024 <a href="https://arxiv.org/pdf/2401.08627" target=&ldquo;blank&rdquo;>[PDF]</a> <a href="https://github.com/haoyuli02/SymGNN" target=&ldquo;blank&rdquo;>[Code]</a><br /></p>
</li>
<li><p>PaGE-Link: Graph Neural Network Explanation for Heterogeneous Link Prediction <br />
<b>Shichang Zhang</b>, Jiani Zhang, Xiang Song, Soji Adeshina, Da Zheng, Christos Faloutsos, Yizhou Sun <br />
WWW 2023 <a href="https://arxiv.org/pdf/2302.12465.pdf" target=&ldquo;blank&rdquo;>[PDF]</a> <a href="https://github.com/amazon-science/page-link-path-based-gnn-explanation" target=&ldquo;blank&rdquo;>[Code]</a><br />  </p>
</li>
<li><p>GStarX: Explaining Graph Neural Networks with Structure-Aware Cooperative Games <br />
<b>Shichang Zhang</b>, Neil Shah, Yozen Liu, Yizhou Sun <br />
NeurIPS 2022 <a href="https://arxiv.org/pdf/2201.12380" target=&ldquo;blank&rdquo;>[PDF]</a> <a href="https://github.com/ShichangZh/GStarX" target=&ldquo;blank&rdquo;>[Code]</a><br />  </p>
</li>
<li><p>Graph-less Neural Networks, Teach Old MLPs New Tricks via Distillation <br />
<b>Shichang Zhang</b>, Yozen Liu, Yizhou Sun, Neil Shah <br />
ICLR 2022 <a href="https://arxiv.org/pdf/2110.08727.pdf" target=&ldquo;blank&rdquo;>[PDF]</a> <a href="https://github.com/snap-research/graphless-neural-networks" target=&ldquo;blank&rdquo;>[Code]</a><br />  </p>
</li>
</ol>
<p><a href="research.html" target=&ldquo;blank&rdquo;>Full list of publications</a><br /></p>
<h2>Honors and Awards</h2>
<ul>
<li><p>NENLP Outstanding Paper Award, 2025</p>
</li>
<li><p>KDD Outstanding Reviewer (Top 10%, two times for both Aug and Feb cycles), 2025</p>
</li>
<li><p>KDD Excellence in Reviewing (30 in 1551), 2023</p>
</li>
<li><p><a href="https://www.sciencehub.ucla.edu/2023-amazon-fellows/" target=&ldquo;blank&rdquo;>Amazon Fellow</a>, 2023</p>
</li>
<li><p><a href="https://www.jpmorgan.com/technology/artificial-intelligence/research-awards/phd-fellowship-2023" target=&ldquo;blank&rdquo;>J.P. Morgan Chase AI PhD Fellowship</a>, 2023</p>
</li>
<li><p><a href="https://research.snap.com/fellowships.html" target=&ldquo;blank&rdquo;>Snap Research Fellowship Honorable Mention</a>, 2022</p>
</li>
<li><p>ICML Top Reviewer (Top 10%), 2022</p>
</li>
<li><p>UCLA Graduate Division Fellowship, 2021</p>
</li>
</ul>
</td>
</tr>
</table>
</body>
</html>
