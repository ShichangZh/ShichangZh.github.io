# jemdoc: menu{MENU}{index.html}, nofooter 
= Shichang (Ray) Zhang 

~~~
{}{img_left}{img/bio2.jpg}{alt text}{280}{320}{https://shichangzh.github.io/}

=== 
{{<span style="color:red; font-size:120%">I am on the academic job market for the 2025 to 2026 cycle. If you believe I am a good fit for a position, please don't hesitate to reach out.}} \n
[cv/shichang_zhang_CV.pdf \[CV\]] [https://drive.google.com/file/d/1kRY7HHc54eScmcCyeVQJoRkPgeimRV5i/view?usp=drive_link \[Research Statement\]] [https://drive.google.com/file/d/1FopvxdYuSq7YW3zk5qjc-ovGYJrsVIiW/view?usp=drive_link \[Teaching Statement\]] [https://neurips.cc/virtual/2025/loc/san-diego/109599 \[Talk Sample 1 (need to login to NeurIPS)\]][https://www.youtube.com/watch?v=CSOPpdDn03M \[Talk Sample 2\]]

=== {{<span style="font-size:120%">Contact}}
{{<span style="font-size:120%">
Science and Engineering Complex (SEC) 6.220, 150 Western Ave, Boston, MA 02134 }} \n
E-mail: /shzhang/ AT hbs DOT edu \n

[https://scholar.google.com/citations?hl=en&user=TYqG0x4AAAAJ&view_op=list_works&sortby=pubdate \[Google Scholar\]] [https://github.com/ShichangZh \[GitHub\]] [https://www.linkedin.com/in/shichang-ray-zhang-4430a4106/ \[LinkedIn\]] [https://x.com/shichangzhang \[X\]]
~~~


== About Me
I am Shichang (Ray) Zhang. I am a postdoctoral fellow at the [https://d3.harvard.edu/ D^3 Institute at Harvard University] working with Professor [https://himalakkaraju.github.io/ Hima Lakkaraju]. I received my Ph.D. in Computer Science from [http://www.ucla.edu/ University of California, Los Angeles (UCLA)] advised by Professor [http://web.cs.ucla.edu/~yzsun/ Yizhou Sun]. My Ph.D. research was generously supported by the [https://www.jpmorgan.com/technology/artificial-intelligence/research-awards/phd-fellowship-2023 J.P. Morgan Chase AI Ph.D. Fellowship] and the [https://www.sciencehub.ucla.edu/2023-amazon-fellows/ Amazon Fellowship]. Before UCLA, I received my M.S. and B.A., both in Statistics, from [https://statistics.stanford.edu/ Stanford] and [https://statistics.berkeley.edu/ Berkeley], respectively. 

My research aims to *scientifically understand AI to ensure it is trustworthy and beneficial to humanity*. I have developed principled methods to analyze and improve the trustworthiness of AI systems across the *full spectrum*, from model mechanisms to training processes to data features. 
(1) Model-wise, I study large language models (LLMs) to reveal their [https://arxiv.org/pdf/2504.02904 internal mechanisms] and [https://arxiv.org/pdf/2307.10635v2 reasoning capabilities], enabling task-specific [https://arxiv.org/pdf/2406.09612 interpretable models] built on them. (2) Training-wise,  I develop techniques to measure the training influence on AI behavior, providing new tools for [https://openreview.net/pdf?id=ghp4GWDFd1 training data assessment], [https://arxiv.org/pdf/2506.00175 model auditing, and credit assignment to developers]. (3) Data-wise, I design methods to [https://arxiv.org/pdf/2201.12380 examine how data features drive AI decisions], allowing non-expert users to interpret and effectively use AI in [https://pubsonline.informs.org/doi/abs/10.1287/isre.2023.0029?journalCode=isre healthcare], [https://arxiv.org/pdf/2401.08627 science], and [https://arxiv.org/pdf/2302.12465 e-commerce] applications. 
Collectively, my research moves beyond black-box empiricism toward a holistic scientific understanding for trustworthy AI




# During my Ph.D. at UCLA, I organized the Data Mining Reading Group for two years. Slides and recordings of the reading groups can be found [https://ucla-dm.github.io/DM_website/reading/course.html here]. My presentations at the reading group can be found under [talks.html Talks].

# , where I held cutting-edge research papers readings, AI course studies, and hosted 13 guest speakers from both academia and industry. The AI courses we covered included neurosymbolic methods, diffusion models, large language models, differential geometry, spectral graph theory, neural radiance fields, and many more. 

# Please feel free to email me if you are interested in becoming a guest speaker. We especially welcome senior-year PhDs to practice their job talks and the first authors to present their recent work published in top conferences.



# == What's New
# - \[Dec 2025\] Give a tutorial talk on explainable AI at NeurIPS 2025 [https://shichangzh.github.io/xaiTutorial/ \[website\]].
# - \[July 2025\] Our paper on A Mechanistic View of How Post-Training Reshapes LLMs has been accepted by COLM 2025. [https://arxiv.org/pdf/2504.02904 \[PDF\]]\n
# - \[June 2025\] Selected as one of the top 10% of reviewers for KDD 2025 again for the February cycle. \n
# - \[Apr 2025\] Our paper on A Mechanistic View of How Post-Training Reshapes LLMs has won the NENLP 2025 *Outstanding Paper Award*. [https://arxiv.org/pdf/2504.02904 \[PDF\]][slides/2025_04_NENLP.pdf \[slides\]]
# - \[Apr 2025\] Our paper on A Mechanistic View of How Post-Training Reshapes LLMs has been selected as Oral presentation for NENLP 2025.
# - \[Apr 2025\] Give a talk on AI Interpretability at Georgia Institute of Technology.
# - \[Apr 2025\] Give a talk on AI Interpretability at Emory University.
# - \[Feb 2025\] Serving as an Area Chair for ACL ARR 2025.
# - \[Feb 2025\] Our paper on Advancing Interpretability by Unifying Feature, Data and Model Component Attribution is on arXiv now. [https://arxiv.org/pdf/2501.18887 \[PDF\]]

# [news.html Find out older news]



== Selected Publications and Preprints
. How Post-Training Reshapes LLMs: A Mechanistic View on Knowledge, Truthfulness, Refusal, and Confidence \n
Hongzhe Du\*, Weikai Li\*, Min Cai, Karim Saraipour, Zimin Zhang, Himabindu Lakkaraju, Yizhou Sun, *Shichang Zhang* (\*equal contribution) \n
COLM 2025 (NENLP *Outstanding Paper*) [https://arxiv.org/pdf/2504.02904 \[PDF\]] [https://github.com/HZD01/post-training-mechanistic-analysis \[Code\]] [slides/2025_04_NENLP.pdf \[slides\]]\n
. Towards Unified Attribution in Explainable AI, Data-Centric AI, and Mechanistic Interpretability \n
*Shichang Zhang*, Tessa Han, Usha Bhalla, Himabindu Lakkaraju \n
Preprint, Under Review [https://arxiv.org/pdf/2501.18887 \[PDF\]]\n
. Who Gets Credit or Blame? Attributing Accountability in Modern AI Systems \n
*Shichang Zhang*, Hongzhe Du, Jiaqi W. Ma, Himabindu Lakkaraju \n 
Preprint, Under Review [https://arxiv.org/pdf/2506.00175 \[PDF\]]\n
. Automated Molecular Concept Generation and Labeling with Large Language Models \n
Zimin Zhang\*, Qianli Wu\*, Botao Xia\*, Fang Sun, Ziniu Hu, Yizhou Sun, *Shichang Zhang* (\*equal contribution) \n
COLING 2025 [https://arxiv.org/pdf/2406.09612 \[PDF\]] [https://github.com/ziminz19/AutoMolCo \[Code\]]\n
. An Explainable AI Approach using Graph Learning to Predict ICU Length of Stay \n
Tianjian Guo, Indranil Bardhan, Ying Ding, *Shichang Zhang* \n
ISR Oct. 2024 [https://pubsonline.informs.org/doi/epdf/10.1287/isre.2023.0029 \[PDF (official)\]] [https://shichangzh.github.io/preprints/LoS_XAI_ISR.pdf \[PDF (preprint)\]]\n
. Predicting and Interpreting Energy Barriers of Metallic Glasses with Graph Neural Networks \n
Haoyu Li\*, *Shichang Zhang\**, Longwen Tang, Mathieu Bauchy, Yizhou Sun (\*equal contribution) \n
ICML 2024 [https://arxiv.org/pdf/2401.08627 \[PDF\]] [https://github.com/haoyuli02/SymGNN \[Code\]]\n
. PaGE-Link: Graph Neural Network Explanation for Heterogeneous Link Prediction \n
*Shichang Zhang*, Jiani Zhang, Xiang Song, Soji Adeshina, Da Zheng, Christos Faloutsos, Yizhou Sun \n
WWW 2023 [https://arxiv.org/pdf/2302.12465.pdf \[PDF\]] [https://github.com/amazon-science/page-link-path-based-gnn-explanation \[Code\]]\n  
. GStarX: Explaining Graph Neural Networks with Structure-Aware Cooperative Games \n
*Shichang Zhang*, Neil Shah, Yozen Liu, Yizhou Sun \n
NeurIPS 2022 [https://arxiv.org/pdf/2201.12380 \[PDF\]] [https://github.com/ShichangZh/GStarX \[Code\]]\n  
. Graph-less Neural Networks, Teach Old MLPs New Tricks via Distillation \n
*Shichang Zhang*, Yozen Liu, Yizhou Sun, Neil Shah \n
ICLR 2022 [https://arxiv.org/pdf/2110.08727.pdf \[PDF\]] [https://github.com/snap-research/graphless-neural-networks \[Code\]]\n  

[research.html Full list of publications]\n


== Honors and Awards
- NENLP Outstanding Paper Award, 2025
- KDD Outstanding Reviewer (Top 10\%, two times for both Aug and Feb cycles), 2025
- KDD Excellence in Reviewing (30 in 1551), 2023
- [https://www.sciencehub.ucla.edu/2023-amazon-fellows/ Amazon Fellow], 2023
- [https://www.jpmorgan.com/technology/artificial-intelligence/research-awards/phd-fellowship-2023 J.P. Morgan Chase AI PhD Fellowship], 2023
- [https://research.snap.com/fellowships.html Snap Research Fellowship Honorable Mention], 2022
- ICML Top Reviewer (Top 10\%), 2022
- UCLA Graduate Division Fellowship, 2021


#~~~
#{}{raw}
#<div style="font-size: 0.9em; font-style: italic; margin-top: 20px; padding: 10px; border-left: 3px solid #ccc;">
#"The product of mathematics is clarity and understanding." - William Thurston
#</div>
#~~~
